# Exercises

## 1  - Producer and Consumer in Confluent Cloud

**Prompt:** Create a simple producer to stream data from a [Kaggle dataset](https://www.kaggle.com/datasets/vodclickstream/netflix-audience-behaviour-uk-movies) capturing UK user behavior on Netflix browsing activity to Confluent Cloud. Ensure the data is serialized in AVRO format before streaming.

## 2 - Movie Analysis Pipeline
**Prompt:** Use Confluent Cloud for Apache Flink to:
1. Calculate the average watch duration for each movie title across all users.
2. Analyze daily engagement patterns for each movie title. Calculate **daily** view counts and total watch time for each title to track how user interest fluctuates day by day.

# Solution

## Prerequisites
Ensure you have the following installed:

- [Java Development Kit (JDK)](https://www.oracle.com/java/technologies/javase-jdk11-downloads.html) (version 11 or higher)
- [Gradle](https://gradle.org/install/) (optional, as the project includes a Gradle Wrapper)

## Confluent Cloud Setup

### 1. Create a cluster
A Basic cluster should be sufficent for this example.

### 2. Create a topic
Name the topic `netflix_audience_behaviour_uk_movies`

### 3. Create a cluster API key
Add the following ACLs
| Type           | Name                                 | Pattern type | Operation | Permission |
| -------------- | ------------------------------------ | ------------ | --------- | ---------- |
| Topic          | netflix_audience_behaviour_uk_movies | Literal      | Write     | Allow      |
| Consumer Group | java-group-1                         | Literal      | Describe  | Allow      |
| Consumer Group | java-group-1                         | Literal      | Read      | Allow      |

**Important:** Take a note of the:
- API Key
- API secret
- Bootstrap server

These will be used in your `client.properties`

### 4. Create a schema registry API key
**Important:** Take a note of the:
- API Key
- API secret

These will be used in your `client.properties`

### 5. Create a client
1. Select *Java Client*
2. Enter the API key and topic

At this point either take note of the client ID or copy the contents of the `client.properties`

## Installation

### 1. Clone the repository:

   ```bash
   git clone https://github.com/andyRokit/confluent_flink_excercise.git
   cd confluent_flink_excercise
   ```

### 2. Run the Gradle wrapper: 
If you do not have Gradle installed, you can use the Gradle Wrapper included in the project.

For Unix/Linux/macOS:

  ```bash
  ./gradlew build
  ```

For Windows

  ```bash
  .\gradlew.bat build
  ```

### 3. Update the properties
Intert the properties recorded from earlier in the process into `client.properties`

**Note:** The example contains additional properties beyond those generated by the client process.

## Running the producer

After building the project, you can run it using the following command:

For Unix/Linux/macOS:
   ```bash
   ./gradlew run
   ```
For Windows:
   ```bash
   .\gradlew.bat run
   ```

## Flink Queries
Once some data has been uploaded the following streaming queries can be used to perform the required analysis for the exercies.

### 1. Calculate the average watch duration for each movie title across all users.

  ```sql
  SELECT
    `title`,
    `movie_id`,
    avg(`duration`) as `avg_duration`
  FROM `default`.`confluent_technical_interview_flink`.`netflix_audience_behaviour_uk_movies`
  GROUP BY `title`, `movie_id`;
  ```

### 2. Analyze daily engagement patterns for each movie title. Calculate **daily** view counts and total watch time for each title to track how user interest fluctuates day by day.

  ```sql
  SELECT
    `title`,
    `movie_id`,
    TO_DATE (`datetime`) AS `viewed_date`,
    COUNT(*) AS `daily_views`,
    SUM(duration) AS `total_watch_time`
  FROM `default`.`confluent_technical_interview_flink`.`netflix_audience_behaviour_uk_movies`
  GROUP BY `title`, `movie_id`, TO_DATE (`datetime`)
  ```